Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Fong2019,
abstract = {A supervised learning algorithm searches over a set of functions A → B parametrised by a space P to find the best approximation to some ideal function f:A → B. It does this by taking examples (a, f(a)) ϵ A × B, and updating the parameter according to some rule. We define a category where these update rules may be composed, and show that gradient descent-with respect to a fixed step size and an error function satisfying a certain property-defines a monoidal functor from a category of parametrised functions to this category of update rules. A key contribution is the notion of request function. This provides a structural perspective on backpropagation, giving a broad generalisation of neural networks and linking it with structures from bidirectional programming and open games.},
archivePrefix = {arXiv},
arxivId = {1711.10455},
author = {Fong, Brendan and Spivak, David and Tuyeras, Remy},
doi = {10.1109/LICS.2019.8785665},
eprint = {1711.10455},
isbn = {9781728136080},
issn = {10436871},
journal = {Proceedings - Symposium on Logic in Computer Science},
pages = {1--17},
title = {{Backprop as Functor: A compositional perspective on supervised learning}},
volume = {2019-June},
year = {2019}
}
