Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Berkhahn2019,
abstract = {We present a new flavor of Variational Autoencoder (VAE) that interpolates seamlessly between unsupervised, semi-supervised and fully supervised learning domains. We show that unlabeled datapoints not only boost unsupervised tasks, but also the classification performance. Vice versa, every label not only improves classification, but also unsupervised tasks. The proposed architecture is simple: A classification layer is connected to the topmost encoder layer, and then combined with the resampled latent layer for the decoder. The usual evidence lower bound (ELBO) loss is supplemented with a supervised loss target on this classification layer that is only applied for labeled datapoints. This simplicity allows for extending any existing VAE model to our proposed semi-supervised framework with minimal effort. In the context of classification, we found that this approach even outperforms a direct supervised setup.},
archivePrefix = {arXiv},
arxivId = {1908.03015},
author = {Berkhahn, Felix and Keys, Richard and Ouertani, Wajih and Shetty, Nikhil and Gei{\ss}ler, Dominik},
eprint = {1908.03015},
title = {{One Model To Rule Them All}},
url = {http://arxiv.org/abs/1908.03015},
year = {2019}
}
