Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Kasim2020,
abstract = {Computer simulations are invaluable tools for scientific discovery. However, accurate simulations are often slow to execute, which limits their applicability to extensive parameter exploration, large-scale data analysis, and uncertainty quantification. A promising route to accelerate simulations by building fast emulators with machine learning requires large training datasets, which can be prohibitively expensive to obtain with slow simulations. Here we present a method based on neural architecture search to build accurate emulators even with a limited number of training data. The method successfully accelerates simulations by up to 2 billion times in 10 scientific cases including astrophysics, climate science, biogeochemistry, high energy density physics, fusion energy, and seismology, using the same super-architecture, algorithm, and hyperparameters. Our approach also inherently provides emulator uncertainty estimation, adding further confidence in their use. We anticipate this work will accelerate research involving expensive simulations, allow more extensive parameters exploration, and enable new, previously unfeasible computational discovery.},
archivePrefix = {arXiv},
arxivId = {2001.08055},
author = {Kasim, M F and Watson-Parris, D and Deaconu, L and Oliver, S and Hatfield, P and Froula, D H and Gregori, G and Jarvis, M and Khatiwala, S and Korenaga, J and Topp-Mugglestone, J and Viezzer, E and Vinko, S M},
eprint = {2001.08055},
title = {{Up to two billion times acceleration of scientific simulations with deep neural architecture search}},
url = {http://arxiv.org/abs/2001.08055},
year = {2020}
}
